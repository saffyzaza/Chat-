import { NextRequest, NextResponse } from 'next/server';
import { Pool } from 'pg';
import { minioClient, MINIO_BUCKET, buildObjectName } from '@/lib/minio';
import { GoogleGenerativeAI } from '@google/generative-ai';

// Polyfills for pdf-parse in Node.js environment
if (typeof (global as any).DOMMatrix === 'undefined') {
  (global as any).DOMMatrix = class {};
}
if (typeof (global as any).ImageData === 'undefined') {
  (global as any).ImageData = class {};
}
if (typeof (global as any).Path2D === 'undefined') {
  (global as any).Path2D = class {};
}

// à¸¢à¹‰à¸²à¸¢ imports à¸—à¸µà¹ˆà¸­à¸²à¸ˆà¸¡à¸µà¸›à¸±à¸à¸«à¸²à¹ƒà¸™à¸šà¸²à¸‡ environment à¹„à¸›à¹‚à¸«à¸¥à¸”à¹à¸šà¸š dynamic à¸ à¸²à¸¢à¹ƒà¸™ handler
// import * as pdfParse from 'pdf-parse';
// import mammoth from 'mammoth';

// PostgreSQL connection pool (consistent with other routes)
const pool = new Pool({
  host: process.env.DB_HOST || 'localhost',
  port: parseInt(process.env.DB_PORT || '5432'),
  database: process.env.DB_NAME || 'chat-aio',
  user: process.env.DB_USER || 'postgres',
  password: process.env.DB_PASSWORD || '1234',
  max: 20,
  idleTimeoutMillis: 30000,
  connectionTimeoutMillis: 2000,
});

export async function GET(request: NextRequest) {
  try {
    const { searchParams } = new URL(request.url);
    const fileName = searchParams.get('name');
    const filePath = searchParams.get('path');

    // à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µà¸žà¸²à¸£à¸²à¸¡à¸´à¹€à¸•à¸­à¸£à¹Œ à¹ƒà¸«à¹‰à¸„à¸·à¸™à¸„à¹ˆà¸²à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¸—à¸µà¹ˆà¸¡à¸µà¹ƒà¸™à¸à¸²à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
    if (!fileName || !filePath) {
      const allQuery = `
        SELECT apa_json, file_name, file_path, mime_type, size_bytes, created_at
        FROM file_apa_metadata
        ORDER BY created_at DESC
      `;
      const allResult = await pool.query(allQuery);
      return NextResponse.json({
        success: true,
        count: allResult.rows.length,
        references: allResult.rows.map(row => ({
          apa: row.apa_json,
          meta: {
            file_name: row.file_name,
            file_path: row.file_path,
            mime_type: row.mime_type,
            size_bytes: row.size_bytes,
            created_at: row.created_at,
          }
        }))
      });
    }

    const query = `
      SELECT apa_json, file_name, file_path, mime_type, size_bytes, created_at
      FROM file_apa_metadata
      WHERE file_name = $1 AND file_path = $2
      ORDER BY created_at DESC
      LIMIT 1
    `;

    const result = await pool.query(query, [fileName, filePath]);
    if (result.rows.length === 0) {
      return NextResponse.json({ error: 'APA metadata not found' }, { status: 404 });
    }

    const row = result.rows[0];
    return NextResponse.json({
      success: true,
      apa: row.apa_json,
      meta: {
        file_name: row.file_name,
        file_path: row.file_path,
        mime_type: row.mime_type,
        size_bytes: row.size_bytes,
        created_at: row.created_at,
      },
    });
  } catch (error: any) {
    console.error('Error fetching APA metadata:', error);
    return NextResponse.json({ error: 'Failed to fetch APA metadata' }, { status: 500 });
  }
}

// Generate APA on demand for an existing file
export async function POST(request: NextRequest) {
  console.log('[APA POST] ============ START APA GENERATION REQUEST ============');
  console.log('[APA POST] Request URL:', request.url);
  console.log('[APA POST] Request method:', request.method);
  try {
    console.log('[APA POST] Parsing request body...');
    const body = await request.json();
    console.log('[APA POST] Body received:', body);
    const fileName: string = body?.name;
    const filePath: string = body?.path;

    console.log(`[APA POST] Received: fileName="${fileName}", filePath="${filePath}"`);

    if (!fileName || !filePath) {
      console.error('[APA POST] Missing parameters');
      return NextResponse.json({ error: 'Missing parameters: name and path required' }, { status: 400 });
    }

    // Fetch file from MinIO
    let buffer: Buffer;
    try {
      console.log(`[APA POST] Fetching from MinIO...`);
      const objectName = buildObjectName(filePath, fileName);
      console.log(`[APA POST] Object name: ${objectName}`);
      const stream = await minioClient.getObject(MINIO_BUCKET, objectName);
      const chunks: Buffer[] = [];
      buffer = await new Promise((resolve, reject) => {
        stream.on('data', (d: Buffer) => chunks.push(d));
        stream.on('end', () => resolve(Buffer.concat(chunks)));
        stream.on('error', (err: any) => reject(new Error(`MinIO error: ${err.message}`)));
      });
      console.log(`[APA POST] âœ“ MinIO fetch successful: ${buffer.length} bytes`);
    } catch (minioErr: any) {
      console.error('[APA POST] âœ— MinIO fetch error:', minioErr);
      return NextResponse.json({ error: `Failed to fetch file from storage: ${minioErr.message}` }, { status: 500 });
    }

    // Guess mime based on extension
    const lowerName = fileName.toLowerCase();
    const isPdf = lowerName.endsWith('.pdf');
    const isDocx = lowerName.endsWith('.docx');
    const isTextLike = lowerName.endsWith('.txt') || lowerName.endsWith('.md') || lowerName.endsWith('.json');

    console.log(`[APA POST] File type detection: isPdf=${isPdf}, isDocx=${isDocx}, isTextLike=${isTextLike}`);

    let textContent: string | null = null;
    let extractionMethod = 'none';
    
    try {
      if (isPdf) {
        try {
          // Dynamic load to avoid DOMMatrix error in Node environment
          const pdfParse = require('pdf-parse');
          const parsed: any = await pdfParse(buffer);
          textContent = parsed?.text || null;
          if (textContent && textContent.trim().length > 0) {
            extractionMethod = 'pdf-parse';
          }
        } catch (pdfErr) {
          // pdf-parse failed or empty
          console.error('[APA POST] pdf-parse error:', pdfErr);
          textContent = null;
        }
      } else if (isDocx) {
        // Dynamic load mammoth
        const mammoth = require('mammoth');
        const result = await mammoth.extractRawText({ buffer });
        textContent = result?.value || null;
        if (textContent) extractionMethod = 'mammoth';
      } else if (isTextLike) {
        textContent = buffer.toString('utf-8');
        if (textContent) extractionMethod = 'buffer-utf8';
      }
    } catch (extractErr: any) {
      textContent = null;
    }

    // Always try Vision API if text extraction failed OR if it's a PDF (force for all PDFs)
    const shouldTryVision = (!textContent || textContent.trim().length === 0) || isPdf;
    
    if (shouldTryVision) {
      const genAIKey = process.env.NEXT_PUBLIC_GOOGLE_API_KEY || process.env.GOOGLE_API_KEY;
      
      if (!genAIKey) {
        console.error('[APA POST] âŒ Cannot use Vision API - Google API key not found in environment');
        console.error('[APA POST] Please set NEXT_PUBLIC_GOOGLE_API_KEY or GOOGLE_API_KEY');
      } else {
        console.log('[APA POST] ðŸ”‘ Google API key found, attempting Vision API...');
        try {
          const base64Data = buffer.toString('base64');
          console.log(`[APA POST] ðŸ“¦ Base64 encoded: ${base64Data.length} characters`);
          
          const genAI = new GoogleGenerativeAI(genAIKey);
          const visionModel = genAI.getGenerativeModel({ model: 'gemini-3-flash-preview' });
          console.log('[APA POST] âœ“ Vision model created: gemini-3.0-flash');
          
          let mimeType = 'text/plain';
          if (isPdf) mimeType = 'application/pdf';
          else if (lowerName.endsWith('.jpg') || lowerName.endsWith('.jpeg')) mimeType = 'image/jpeg';
          else if (lowerName.endsWith('.png')) mimeType = 'image/png';
          else if (lowerName.endsWith('.gif')) mimeType = 'image/gif';
          else if (lowerName.endsWith('.webp')) mimeType = 'image/webp';
          
          console.log(`[APA POST] ðŸ“¤ Sending to Vision API: mimeType=${mimeType}`);
          
          const visionResponse = await visionModel.generateContent([
            {
              inlineData: {
                mimeType: mimeType,
                data: base64Data,
              },
            },
            {
              text: 'Extract ALL TEXT from this document. Return the complete, full text content exactly as it appears:',
            },
          ]);
          
          console.log('[APA POST] ðŸ“¥ Vision API response received');
          const visionText = visionResponse.response.text();
          console.log(`[APA POST] ðŸ“„ Vision extracted: ${visionText.length} characters`);
          
          if (visionText && visionText.trim().length > 0) {
            textContent = visionText;
            extractionMethod = 'vision-api';
            console.log('[APA POST] âœ… Vision API SUCCESS');
          } else {
            console.warn('[APA POST] âš ï¸ Vision API returned empty text');
          }
        } catch (visionErr: any) {
          console.error('[APA POST] âŒ Vision API ERROR:', visionErr.message);
          console.error('[APA POST] Error details:', visionErr);
        }
      }
    }

    console.log(`[APA POST] File: ${fileName}, Type: ${isPdf ? 'PDF' : isDocx ? 'DOCX' : isTextLike ? 'TEXT' : 'OTHER'}, Method: ${extractionMethod}, Length: ${textContent?.length || 0}`);
    if (!textContent || textContent.trim().length === 0) {
      console.warn(`[APA POST] WARNING: No text extracted from ${fileName} by any method.`);
    }

    const genAIKey = process.env.NEXT_PUBLIC_GOOGLE_API_KEY || process.env.GOOGLE_API_KEY;
    if (!genAIKey) {
      return NextResponse.json({ error: 'Google API key not configured' }, { status: 500 });
    }

    let apaJson: any = null;
    try {
      const genAI = new GoogleGenerativeAI(genAIKey);
      const modelName = process.env.GEMINI_MODEL || 'gemini-3-flash-preview';
      const model = genAI.getGenerativeModel({ model: modelName });

      const schemaDescription = `SYSTEM ROLE
à¸„à¸¸à¸“à¸„à¸·à¸­à¸œà¸¹à¹‰à¸Šà¹ˆà¸§à¸¢à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¹€à¸­à¸à¸ªà¸²à¸£à¸§à¸´à¸Šà¸²à¸à¸²à¸£à¸ªà¸³à¸«à¸£à¸±à¸šà¸£à¸°à¸šà¸šà¸à¸²à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸‡à¸²à¸™à¸§à¸´à¸ˆà¸±à¸¢à¸£à¸°à¸”à¸±à¸š production

TASK
à¸­à¹ˆà¸²à¸™à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸ˆà¸²à¸à¹€à¸­à¸à¸ªà¸²à¸£à¸§à¸´à¸Šà¸²à¸à¸²à¸£à¸—à¸µà¹ˆà¹ƒà¸«à¹‰à¸¡à¸² à¹à¸¥à¹‰à¸§à¹à¸›à¸¥à¸‡à¹€à¸›à¹‡à¸™ JSON à¸•à¸²à¸¡ schema à¸—à¸µà¹ˆà¸à¸³à¸«à¸™à¸”
à¹ƒà¸Šà¹‰à¹€à¸‰à¸žà¸²à¸°à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸›à¸£à¸²à¸à¸à¹ƒà¸™à¹€à¸­à¸à¸ªà¸²à¸£à¸ˆà¸£à¸´à¸‡à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™

STRICT RULES (à¸ªà¸³à¸„à¸±à¸à¸¡à¸²à¸)
1. à¸šà¸—à¸„à¸±à¸”à¸¢à¹ˆà¸­ (abstract) à¸•à¹‰à¸­à¸‡à¹€à¸›à¹‡à¸™à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸—à¸µà¹ˆà¸›à¸£à¸²à¸à¸à¹ƒà¸™à¹€à¸­à¸à¸ªà¸²à¸£à¸ˆà¸£à¸´à¸‡à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™
2. à¸«à¹‰à¸²à¸¡à¹à¸•à¹ˆà¸‡ à¸«à¹‰à¸²à¸¡à¸ªà¸£à¸¸à¸› à¸«à¹‰à¸²à¸¡à¹€à¸£à¸µà¸¢à¸šà¹€à¸£à¸µà¸¢à¸‡à¹ƒà¸«à¸¡à¹ˆ à¸«à¹‰à¸²à¸¡à¸­à¸™à¸¸à¸¡à¸²à¸™
3. à¸«à¸²à¸à¸žà¸šà¸šà¸—à¸„à¸±à¸”à¸¢à¹ˆà¸­ à¹ƒà¸«à¹‰à¸„à¸±à¸”à¸¥à¸­à¸à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¹€à¸•à¹‡à¸¡ (à¸£à¸§à¸¡à¸„à¸³à¸§à¹ˆà¸² "à¸šà¸—à¸„à¸±à¸”à¸¢à¹ˆà¸­")
4. à¸«à¸²à¸à¹„à¸¡à¹ˆà¸žà¸šà¸šà¸—à¸„à¸±à¸”à¸¢à¹ˆà¸­ à¹ƒà¸«à¹‰à¹ƒà¸ªà¹ˆà¸„à¹ˆà¸² null
5. à¸«à¹‰à¸²à¸¡à¹ƒà¸Šà¹‰à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸à¸Šà¸·à¹ˆà¸­à¹„à¸Ÿà¸¥à¹Œ à¸„à¸§à¸²à¸¡à¸£à¸¹à¹‰à¹€à¸”à¸´à¸¡ à¸«à¸£à¸·à¸­à¸à¸²à¸£à¸„à¸²à¸”à¹€à¸”à¸²
6. à¸«à¹‰à¸²à¸¡à¹ƒà¸Šà¹‰à¸„à¸³à¸§à¹ˆà¸² inferred, likely, based on filename, suggests
7. à¸«à¸²à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸”à¹„à¸¡à¹ˆà¸›à¸£à¸²à¸à¸à¸Šà¸±à¸” à¹ƒà¸«à¹‰à¹ƒà¸Šà¹‰ null à¸«à¸£à¸·à¸­ [] à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™
8. à¹€à¸­à¸²à¹€à¸‰à¸žà¸²à¸°à¸ à¸²à¸©à¸²à¹„à¸—à¸¢ abstract

KEYWORDS
- à¸”à¸¶à¸‡à¹€à¸‰à¸žà¸²à¸°à¸„à¸³à¸ªà¸³à¸„à¸±à¸à¸—à¸µà¹ˆà¸›à¸£à¸²à¸à¸à¹ƒà¸™à¹€à¸­à¸à¸ªà¸²à¸£
- à¸«à¸²à¸à¹„à¸¡à¹ˆà¸žà¸š à¹ƒà¸«à¹‰à¹€à¸›à¹‡à¸™ array à¸§à¹ˆà¸²à¸‡

RESEARCHERS
- à¸£à¸°à¸šà¸¸à¹€à¸‰à¸žà¸²à¸°à¸£à¸²à¸¢à¸Šà¸·à¹ˆà¸­à¸—à¸µà¹ˆà¸›à¸£à¸²à¸à¸à¹ƒà¸™à¹€à¸­à¸à¸ªà¸²à¸£
- à¸«à¸²à¸à¹„à¸¡à¹ˆà¸žà¸š à¹ƒà¸«à¹‰à¹€à¸›à¹‡à¸™ []

OUTPUT FORMAT
- à¸ªà¹ˆà¸‡à¸­à¸­à¸à¹€à¸‰à¸žà¸²à¸° JSON à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™
- à¸•à¹‰à¸­à¸‡ parse à¹„à¸”à¹‰à¸—à¸±à¸™à¸—à¸µ
- à¸«à¹‰à¸²à¸¡à¸¡à¸µà¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸­à¸˜à¸´à¸šà¸²à¸¢à¸™à¸­à¸ JSON

OUTPUT SCHEMA (à¸•à¹‰à¸­à¸‡à¸•à¸£à¸‡à¸—à¸¸à¸ field)
{
  "abstract": null,
  "keywords": {
    "thai": [],
    "english": []
  },
  "references": [],
  "projectInfo": {
    "titleThai": null,
    "titleEnglish": null,
    "proposalCode": null,
    "budgetYear": null,
    "university": null,
    "projectCode": null,
    "totalBudget": null,
    "otherInfo": null
  },
  "researchers": [],
  "documentType": "",
  "additionalInfo": null
}`;
      const basePrompt = `You are an expert researcher analyzing a document. Your task is to EXTRACT ALL INFORMATION COMPLETELY AND ACCURATELY. ${schemaDescription}`;
      const contentForModel = textContent && textContent.trim().length > 0
        ? `File: ${fileName}\nContent:\n${textContent.substring(0, 20000)}`
        : `File: ${fileName}\nNo readable text could be extracted. If you can infer the document type from the filename, provide basic metadata. Filename: ${fileName}`;

      const result = await model.generateContent(`${basePrompt}\n\n${contentForModel}`);
      const text = result.response?.text?.() || '';
      console.log('[APA POST] Text extracted length:', textContent?.length || 0);
      console.log('[APA POST] AI response sample:', text.substring(0, 300));
      try {
        const firstBrace = text.indexOf('{');
        const lastBrace = text.lastIndexOf('}');
        const jsonStr = firstBrace >= 0 && lastBrace >= 0 ? text.slice(firstBrace, lastBrace + 1) : text;
        apaJson = JSON.parse(jsonStr);
      } catch {
        apaJson = { title: fileName, raw: text };
      }
    } catch (aiErr: any) {
      console.error('AI generation error:', aiErr);
      return NextResponse.json({ error: `AI generation failed: ${aiErr.message}` }, { status: 500 });
    }

    // Persist APA JSON
    try {
      await pool.query(
        `DELETE FROM file_apa_metadata WHERE file_name = $1 AND file_path = $2`,
        [fileName, filePath]
      );
      await pool.query(
        `INSERT INTO file_apa_metadata (file_name, file_path, mime_type, size_bytes, apa_json, created_at)
         VALUES ($1, $2, $3, $4, $5::jsonb, NOW())`,
        [fileName, filePath, isPdf ? 'application/pdf' : isDocx ? 'application/vnd.openxmlformats-officedocument.wordprocessingml.document' : 'text/plain', buffer.length, JSON.stringify(apaJson)]
      );
    } catch (dbErr: any) {
      console.error('Database insert error:', dbErr);
      return NextResponse.json({ error: `Database error: ${dbErr.message}` }, { status: 500 });
    }

    return NextResponse.json({ 
      success: true, 
      apa: apaJson,
      debugInfo: {
        fileName,
        fileType: isPdf ? 'PDF' : isDocx ? 'DOCX' : isTextLike ? 'TEXT' : 'OTHER',
        textExtractedLength: textContent?.length || 0,
        extractionMethod: extractionMethod,
        hasContent: textContent && textContent.trim().length > 0
      }
    });
  } catch (error: any) {
    console.error('Error generating APA metadata:', error);
    return NextResponse.json({ error: `Unexpected error: ${error.message}` }, { status: 500 });
  }
}
